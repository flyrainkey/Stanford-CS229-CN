原文：http://cs229.stanford.edu/notes/cs229-notes4.pdf  
翻译：[MIL Learning Group](https://github.com/milLearningGroup/Stanford-CS229-CN) - [Murray0575](https://github.com/Murray0575)  



## Part VI Learning Theory

### 1 Bias/variance tradeoff(权衡偏差与方差）

当我们在上线性回归，曾讨论过这样的问题：在数据拟合的时候，我们是选一个相对简单的模型，如线性的“$y=\theta_0+\theta_1x$",还是选择相对复杂的模型，如多项式“$y=\theta_0+\theta_1x+\cdots\theta_5x^5$".我们来看下面的例子：
![](./image/notes4-bias.jpg)

如最右端的图所示，要用一个5次多项式来拟合数据，我们所得到的并不是一个好的模型。即使这个5次多项式在训练集合中通过$x$（比如说住房面积）能预测出一个非常好的$y$（比如说住房的价格）,但我们并不能知道这个模型能在训练集合外能给出一个好的房价预测。也就是说，这个在训练集合中得出来的好的5次多项式模型并不一定能很好地推广到训练集合外的房子上。一个**假设**（hypothesis）的**泛化误差**（generalization error,稍后将给出正式的定义）是它在所有实例而不一定是训练集合中所得到的**期望方差**（expected error）。

上图中最左边的线性拟合模型与最右边的5次多项式模型都有非常大的泛化误差。但是这两个模型所面临的问题是截然不同的。如果$y$与$x$之间的关系不是线性的，那么即使我们对一大堆训练数据进行线性拟合，所得到的线性模型仍然不能准确捕捉到数据内在的结构。我们现在粗略地将一个模型的**偏差**（bias）定义为期望的泛化误差，即使我们去拟合一个非常大（甚至无限）的训练集合。因此，对于上述问题，这个线性模型具有非常大的偏差，可能是对数据的欠拟合（也就是没有捕捉到数据所体现的结构特征）。

除了偏差，这里还有一个因素构成泛化误差，也就是模型拟合过程中的方差。例如，最右幅图中我们用5次多项式进行拟合就有很大的风险，因为很可能我们拟合的模型碰巧符合我们小规模、有限的训练集合，而并不能反映$x$和$y$之间更广泛的关系。这可能是因为我们只是碰巧有一个比平均房价稍贵的房子，或者是一个比平均房价稍便宜的房子等等。通过拟合这些偶然出现在训练集合中，并不能反映真实情况的伪模式（spurious patterns），我们可能得到一个具有很大的泛化误差的模型。在这种情况下，我们说这个模型有很大的方差$^1$。

通常情况下，偏差与方差之间存在一种权衡。如果我们的模型过于“简单”而且参数又少，那么这个模型可能有很大的偏差（但是方差很小）;如果这个模型太“复杂”，而且有很多的参数，那么可能会有很大的方差（但是有较小的偏差）;在上面的例子中，中间的2次多项式就比线性和5次多项式这两个极端要好。

>$^1$在讲义里，我们不试图给出关于偏差与方差的正式定义。当然，偏差与方差都有直接给出的正式定义，例如在线性回归里。对于两者的定义，有很多不同的提议，至今对哪个是正确或最权威的仍有争议。

### 2 Preliminaries(预备知识)

在这一部分讲义中，我们开始进军机器学习理论知识。本章内容不仅有趣和有启发性，而且还会帮助我们培养机器学习的直觉和在不同背景下如何最佳应用学习算法的经验。此外，我们还会探究一些问题：首先，我们能否就刚讨论过的偏差与方差的权衡做出正式的总结？这个问题最终还会引导我们来讨论关于模型选择的方法，比如这些方法可以在对训练集合拟合时自动确定多项式是几阶的。其次，在机器学习中我们真正关心的实际是泛化误差（generalization error），但是大多数机器学习的算法是用模型去拟合训练集合的。那么为什么在训练集合上拟合的好坏就能告诉我们泛化误差的信息？具体来说，我们能否把训练集合中的误差与泛化误差联系起来？第三点，也是最后一点，是否存在某些条件使得我们能够证明机器学习算法的好坏？

在这我们先给出两条简单但却十分实用的引理（lemmas）。

引理1.一致限（The union bound）。让我们设$A_1,A_2,A_3,...,A_k$是K个不同事件（但可能不是独立的）。那么就有$$P(A_1\cup \cdots \cup A_k)\leq P(A_1)+ \cdots+P(A_k) $$
在概率论中，一致限经常被当做公理（所以我们不试着去证明它），而且它也非常直观：任何k个事件发生的概率最多是K个不同事件概率之和。

引理2.（霍夫丁（Hoeffding)不等式）我们设$Z_1,...,Z_m$是m个遵守伯努利分布(Bernoulli(φ) distribution)的相互独立同分布的随机变量。例如:$P(Z_i=1) = \phi$,和$P(Z_i=0)=1-\phi$.设$\hat{\phi}=(\frac{1}{m})\sum_{i=1}^m Z_i$是这些随机变量的平均值。我们设任意的$\gamma>0$为一固定值。那么有$$P(\mid \phi-\hat{\phi}\mid>\gamma)\leq2exp(-2\gamma^2m)$$这个引理(这个在机器学习里被称为切比雪夫边界(Chernoff  bound))表明，如果我们用m个伯努利随机变量的平均值$\hat{\phi}$作为我们对$\phi$的评估，那么只要m足够大，则我们距离真实值的概率就很大。另外一种表述方式是如果你有一个有偏倚硬币（biased coin），抛出去正面朝上的概率为$\phi$,然后你抛了m次并且计算了正面朝上的比例。如果m很大，那么这个比例很可能是$\phi$的一个很好的评估。

基于这两个引理，我们就能够证明一些在机器学习里很重要很流行的结论。

为了简化起见，我们先关注一下二分类问题，即其中的标签$y\in\{0,1\}$.然后我们即将讲到的所有内容也都会推广到其它问题中,包括回归问题和多类别的分类问题等。

我们假设有一个训练集合$S=\{(x^{(i)},y^{(i)});i=1,...,m\}$,且训练样本$(x^{(i)},y^{(i)})$是符合某概率分布$D$的独立同分布的随机变量。对于一个假设（hypothesis）$h$，我们定义训练误差（在机器学习中也叫经验风险（empirical risk）或经验误差（empirical error））为$$\hat{\varepsilon}(h)=\frac{1}{m}\sum_{i=1}^m1\{h(x^{(i)})\neq y^{(i)}\}$$

这只是假设$h$错误分类所占训练样本的比例。当我们想要直接设$\hat{\varepsilon}(h)$在训练集合S上的依赖关系时，我们可以写作$\hat{\varepsilon}_S(h)$.然后我们也可定义泛化误差为$$\varepsilon(h)=P_{(x,y)\sim D}(h(x)\neq y)$$也就是说，如果我们现在从分布$D$中给出一个新样例$(x,y)$，$\varepsilon(h)$就是假设模型$h$错误分类的概率。

注意这里我们已经假设了训练数据和我们将要去评估假设的数据是来自同一个分布$D$(这一假设存在于对泛化误差的定义中)。这个假设通常也被认为是 **PAC** 假设之一$^2$.

>**PAC**的全称是"probably approximately correct",这是一个框架和一系列假设的集合，在机器学习理论中的很多结构都是基于这些假设而证
明得到的。其中训练集合与测试集合服从同一分
布和训练样本的独立性假设是最重要的两个。

考虑一下线性分类的情况，我们设$h_\theta(x)=1\{\theta^Tx\geq0\}$.那么要拟合参数$\theta$的合理方法是什么呢？一种思路是尽量使训练误差最小，然后选择:$$\hat{\theta}=arg\min_\theta\hat{\varepsilon}(h_\theta)$$.

我们把上面的过程称为**经验风险最小化**（ERM，empirical risk minimization），而基于机器学习算法最终得到的假设就是$\hat{h}=h_\theta$.我们把ERM看做为最“基础”的学习算法,在这一系列的讲义中我们主要关注的就是这种算法。（像逻辑回归等等的算法也可以看作是对 ERM 的某种近似）
在我们机器学习的课程中，这将对从假设的具体参数和问题中抽象出来是十分有用的，比如我们是否要用线性分类之类的问题。我们把学习算法所用到的**假设类**（hypothesis class）$H$定义为所有要考虑的分类器（classifiers）的集合。对于线性分类问题，$H=\{h_\theta:h_\theta(x)=1\{\theta^Tx\geq0\},\theta\in R^{n+1} \}$在$\chi$（输入的域）上的所有分类器的集合，其中所有分类边界都是线性的。更广泛地来说，如果我们学习神经网络，那么我们可以让$H$为能表示一些神经网络结构的所有分类器的集合。

现在，我们就可以把经验风险最小化看成是在函数类$H$上的最小化，其中由学习算法来选择假设：$$\hat{h}=arg\min_{h\in H}\hat{\varepsilon}(h)$$


### 3 The case of finite H

### 4 The case of infinite H