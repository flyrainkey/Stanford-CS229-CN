## Part VII 正则化和模型选择(Regularization and model selection)

假定我们试图为一个学习问题从多个不同的模型进行选择.例如,我们可能使用一个多项式回归模型$h_{\theta}(X)=g(\theta_{0}+\theta_{1}x+\theta{2}x^{2}+\cdots+\theta_{k}x^{k})$,并希望决定k应该取$0,1,\dots,10$中的哪一个.应该如何自动选择一个

模型,使其能够在偏置和方差之间进行良好的折衷？或者,假如我们希望去自动地为局部加权回归(locally weighted regression)选择一个带宽参数(bandwidth parameter) $\tau$ ,以及为L1正则化支持向量机($\ell_{1}$-regularized SVM)选择参数$C$,那么我们该如何做到呢？

为了更加具体,在该笔记中,我们假定我们有一个模型的有限集合$\mathcal{M}=\{M_1,\dots,M_d\}$,我们将在该集合中进行选择.例如,在第一个例子中,模型$M_i$就是第$i$个多项式回归模型(推广至无限集合$\mathcal{M}$并不困难).或者,如果我们要去决定应该使用SVM,神经网络还是逻辑回归,那么$\mathcal{M}$就要包含以上这些模型.

## 1    交叉验证(Cross validation)

和往常一样,假定我们有一个训练集$S$.考虑到我们对经验风险最小化的了解,这里给出一个方法,乍一看像是在模型选择上使用经验风险最小化得来的算法：

1. 在训练集$S$上训练每一个模型$M_i$来得到假设$h_i$.
2. 选择训练误差最小的假设.

这个算法并不会起作用.考虑选择一个多项式的阶数,多项式的阶数越高,它就越能拟合训练集$S$,并得到更小的训练误差.因此,该方法总是会选择高方差、高阶的多项式模型.根据以往来看,这往往不是好的选择.

下面是一个更好的算法.在**保持交叉验证(hold-out cross validation)**(或者叫作**简单交叉验证(simple cross validation)**)的方法中,执行以下步骤：

1. 将$S$随机分为$S_{train}$(比如,70%的数据)和$S_{CV}$(剩余30%的数据).在这里,$S_{CV}$被称为保持交叉验证集(hold-out cross validation set).

2. 仅在$S_{train}$上训练每一个模型$M_i$,得到假设$h_i$.

3. 选择并输出在保持交叉验证集上有最小误差$\hat{\varepsilon}_{S_{CV}}(H_i)$的假设$h_i$.(回想一下,$\hat{\varepsilon}_{S_{CV}}(H_i)$表示$h$在$S_{CV}$中的一组例子上的经验误差).

   ​

通过一组在$S_{CV}​$中,且没有在模型训练时使用的数据进行测试,我们可以更好地估计每个假设$h_i​$的真正泛化误差,并选择其中具有最小估计泛化误差的值.通常,$\frac{1}{4}\thicksim\frac{1}{3}​$的数据用于组成保持交叉验证集,30%是一个典型的选择.

该算法的第三个步骤可以选择性地替换为：通过 $arg min_i \hat{\varepsilon}_{S_{CV}}(H_i)$选择模型$M_i$,并在完整的训练集$S$上重新训练$M_i$.(这通常是一个好的想法,一个例外是当学习算法对初始条件或数据的扰动极为敏感时,该方式不适用.对于这些方法,$M_i$在$S_{train}$上有好的效果并不必然意味着它同样在$S_{CV}$上也会表现出色,而放弃这个重训练的步骤可能会更好.)

保持交叉验证的缺点是它“浪费”了大约30%的数据.即使我们使用了在整个训练集上重新训练模型的可选步骤,我们仍然试图为一个有0.7m个训练样本、而非m个训练样本的学习问题找一个好的模型,因为我们每次都只是测试了一个仅在0.7m个样例上训练过的模型.如果数据丰富或成本很低,这种“浪费”还可以接受,但在数据稀缺的学习问题上(比方说,一个m=20的问题),我们希望能做得更好.

这里有一个被称为**$k-$折交叉验证**(**$k-$fold corss validation**)的方法,每次都会提供更少的数据：

1. 将$S$随机分成$k$个不相交的$m/k$大小的训练样例子集.我们称这些子集为$S_1,\dots,S_k$.

2. 对于每个模型$M_i$,我们作如下评估：

     For $j = 1,\dots,k$

​           在$S_1\cup\cdots\cup S_{j-1}\cup S_{j+1}\cup\cdots S_k$上训练模型$M_i$(即,在除了子集$S_j$的所有数据上进行训练)得到假设$h_{ij}$.

   　　在$S_j$上测试假设$h_ij$得到$\hat{\varepsilon}_{S_{j}}(h_{ij})$.

​       然后计算$\hat{\varepsilon}_{S_{j}}(h_{ij})$的平均值(在j上的平均)作为模型$M_i$的估计泛化误差.

3. 选择估计泛化误差最小的模型$M_i$,然后在训练集$S$上重新训练这个模型.由此产生的假设被输出作为我们最终的答案.

这里使用的折叠次数的一个典型选择是k=10.虽然每次提供的数据部分是全部的$1/k$——比以前更少了,但这个过程也可能比保留交叉验证有更大的计算量,因为我们现在需要对每个模型训练$k$次.

虽然k=10是一个常用的选择,但在数据非常少的问题上,有事我们会使用k=m的极端选择,一遍每次尽可能少地遗漏数据.在这样一个设置中,我们会在除了某一个样例之外的每一个$S$中的训练样例上进行重复训练,并在那个保留的样例上进行测试,然后将得到的$m=k$个误差进行平均,以获得对模型的泛化误差的估计.这种方法有它自己的名字；因为我们每次都保留了一个训练样例,所以该方法被叫做**留一交叉验证**(**leave-one-out cross validation**).

最后,尽管我们将交叉验证的不同版本描述为选择模型的方法,但他们也可以更简单地用于评估单个模型或算法.例如,如果你实现了某个学习算法并想估计其在你的程序中的表现(或者如果你已经发明了一个新颖的学习算法并希望在技术文章中报告它在各种测试集中的表现如何),交叉验证会提供一个比较合理的方法去完成该项评估.

## 2    特征选择(Feature Selection)

特征选择是模型选择的一个特殊且重要的情况.为了说明这一点,想象你有一个监督学习问题,其特征数$n$非常巨大(可能$n\gg m$),但你猜想只有一小部分的特征是对学习目标“有意义的”.即使你针对$n$个输入特征使用一个简单的线性分类器(比如感知机),其假设类的VC维度仍然是$O(n)$,因此过拟合将会是一个潜在的问题,除非训练及相当大.

在这样的背景下,你就能够使用一个特征选择算法来减少特征的数量.给定$n$个特征,有$2^n$个可能的特征子集(因为$n$个特征中的每一个都能被包含在子集中或被子集排除),因此特征选择可化为一个针对$2^n$个可能模型的模型选择问题.对于大的$n$值,明确地列举并比较所有$2^n$个模型通常太过昂贵,因此通常使用一些启发式的搜索程序来找到一个好的特征子集.以下的搜索过程被称为**前向搜索**(**forward search**)：

1. 初始化$\mathcal{F}=\varnothing$.

2. 重复 $\{$

   (a) For $i = 1,\dots,n$ if $i\notin\mathcal{F}$,令 $\mathcal{F_i} = \mathcal{F}\cup\{i\}$,并使用一些版本的交叉验证来评估特征$\mathcal{F_i}$(即,仅使用$\mathcal{F_i}$中的特征来训练你的学习算法,并估计其泛化误差).

   (b)将$\mathcal{F}$设置为步骤(a)中找到的最佳特征子集.

   $\}$

3. 选择并输出在整个搜索过程中评估出的最佳特征子集.

当$\mathcal{F}=\{1,\dots,n\}$是所有特征的集合,或$|\mathcal{F}|$超过了一些预设的阈值(对应于你希望算法考虑使用的最大特征数量)时,该算法的外部循环就会被停止.

这个算法描述里**包装模型特征选择**(**wrapper model feature selection**)的一个实例,因为这是一个“包装”你的学习算法的过程,并重复调用学习算法去评估其使用不同的特征子集时的表现有多好.除了前向搜索,还可以使用其他的搜索过程.例如,从所有特征的集合$\mathcal{F}=\{1,\dots,n\}$开始进行**后向搜索**(**backward search**),并重复一次一个地删除特征(以类似于前向搜索如何评估单特征添加的方式来评估单特征的删除),直到$\mathcal{F}=\varnothing$.

包装特征选择算法通常能工作良好,但考虑到它需要多次调用学习算法,因此包装特征选择算法可能在计算上是昂贵的.的确,完整的前向搜索(在$\mathcal{F}=\{1,\dots,n\}$时终止)需要调用学习算法大约$O(n^2)$次.

**过滤特征选择**(**Filter feature selection**)方法给出了启发式的,但计算上更便宜的选择特征子集的方法.该想法是计算一些简单的分数$S(i)$用于衡量每个特征提供了关于类标签$y$的多少信息.然后,我们简单地选择有最大分数$S(i)$的$k$个特征.

对该分数的一个可能的选择是定义$S(i)$为在训练数据上测量的$x_i$和$y$的相关性(的绝对值).这将导致我们会选择和类标签有最强关联性的特征.在实践中,选择$S(i)$作为$x_i$与$y$之间的**交互信息**(**mutual information**)$\mathrm{MI}(X_i,y)$：

$$\mathrm{MI}(X_i,y)=\sum_{x_i\in\{0,1\}}{\sum_{y\in\{0,1\}}p(X_i,y)\mathrm{log}\frac{p(X_i,y)}{p(X_i)p(y)}} \\$$.

(上面的等式假设$x_i$和$y$是二值的；更一般地说,总和将超出变量的范围.)$p(x_i,y),p(x_i)$和$p(y)$上的概率都可以根据它们在训练集上的经验分布来估计.

为在直觉上得知该得分做了什么,注意交互信息也可以表示为**Kullback-Leibler**(KL)散度：

$$\mathrm{MI}(x_i,y)=\mathrm{KL}(p(x_i,y)||p(x_i)p(y))\\$$

在问题集 #3中你可以使用KL-散度来做更多的事,但在非正式的情况下,这给出了概率分布$p(x_i,y)$和$p(x_i)p(y)$有多不同.如果$x_i$和$y$是独立随机变量,我们就会得到$p(x_i,y)=p(x_i)p(y)$,并且这两个分布的KL-散度将会是零.这和以下想法是一致的：如果$x_i$和$y$是独立的,那么$x_i$对于$y$来说显然是极其“非信息性”的,因此得分$S(i)$应该会小.相反,如果$x_i$对于$y$来说极其“信息性”,那么他们的交互信息$\mathrm{MI}(x_i,y)$会非常大.

一个最后的细节：现在你已经根据这些特征的分数$S(i)$对他们进行了排序,那么你要如何确定有多少特征$k$要去选择？一个标准的方法是使用交叉验证来选择可能的k值.例如,当应用朴素贝叶斯来进行文本分类——在该问题当中,词汇规模$n$通常十分巨大——使用这个方法来选择一个特征子集通常会使分类器准确度提高.

## 3    贝叶斯统计和正则化(Bayesian statistics and regularization)

在这一节中,我们将讨论对抗过拟合的斗争的武器库中的一些工具.

在本节课开始时,我们讨论了使用最大似然(ML)进行参数拟合,并根据以下公式选择我们的参数：

$$\theta_{\mathrm{ML}}=\mathrm{arg  \mathop{max} _{\theta}}\prod_{i=1}p(y^{(i)}|x^{(i)};\theta) \\$$

在接下来的讨论中,我们将$\theta$看作是世界的未知参数.这种“$\theta$是恒定值但未知“的观点在**频率**统计中会被采用.在这个频率论的世界观中,$\theta$并不是随机的——它只是恰好是未知的——我们的工作是提出统计程序(如最大似然)来尝试估计这个参数.

处理我们的参数估计问题的另一种方法是采用**贝叶斯式**的世界观并认为$\theta$是一个值为未知的随机变量.在这个方法中,我们对$\theta$指定一个**先验分布(prior distribution)**$p(\theta)$表示关于参数的”先验信念“.给出一个训练集$S=\{(X^{(i)},y^{(i)})\}_{i=1}^m$,当我们被要求对一个新的$x$值进行预测时,我们可以计算参数的后验分布：

$$\begin{eqnarray*} p(\theta|S)&=&\frac{p(S|\theta)p(\theta)}{p(S)}  \\ &=& \frac{\prod_{i=1}^mp(y^{(i)|x^{(i)}p(\theta)})}{\int_{\theta}(\prod_{i=1}^mp(y^{(i)}|x^{(i)},\theta)p(\theta))d\theta} \tag{1} \end{eqnarray*} \\ $$

在上面这个方程中,$p(y^{(i)}|x^{(i)},\theta)$来自任何你在学习问题中使用过的模型,例如,如果你是用贝叶斯逻辑回归,那么你可能会选择$p(y^{(i)}|x^{(i)},\theta)=h_\theta(x^{(i)})^{y^{(i)}}(1-h_\theta(x^{(i)}))^{(1-y^{(i)})}$,在这里$h_\theta(x^{(i)})=1/(1+\mathrm{exp}(-\theta^Tx^{(i)}))$.

当我们给出一个新的测试例子$x$并要求对其进行与测试,我们可以使用$\theta$上的后验分布来计算类别标签上的后验分布：

$$p(y|x,S)=\int_\theta(y|x,\theta)p(\theta|S)d\theta \tag{2} \\$$

在上面这个方程中,$p(\theta|S)$来自方程(1).因此,例如,如果目标是预测给定$x$的$y$的期望值,那么我们会输出

$$\mathrm{E}[y|x,S]=\int_yyp(y|x,S)dy \\$$

我们在这里概述的程序可以被认为是做”完全贝叶斯“预测,我们的预测是通过对$\theta$上的后验$p(\theta|S)$取平均来计算的.不幸的是,一般来说计算这个后验分布是非常困难的.这是因为它需要对方程(1)中的（通常是高维的)$\theta$进行积分,并且这通常不能以闭合形式完成.

因此在实践中,我们会转而去近似$\theta$的后验分布.一个常见的近似方法使用单点估计替换$\theta$的后验分布(如方程2).这个$\theta$的**最大后验概率MAP(maximum a posteriori)**由以下方程给出：

$$\theta_{\mathrm{MAP}}=arg\mathop{max}_\theta\prod_{i=1}^mp(y^{(i)}|x^{(i)},\theta)p(\theta) \tag{3}\\$$

注意,除了最后的$p(\theta)$项之外,这与对$\theta$的ML(最大似然)估计的公式相同.

在实际应用中,先验$p(\theta)$的一般选择是假设$\theta \sim\mathcal{N}(0,\tau^2I) $.使用这个先验选择,拟合参数$\theta_{\mathrm{MAP}}$将比最大似然选择的范数更小.(参见问题集 #3.) 在实践当中,这将导致贝叶斯MAP估计比ML估计出的擦书更加不容易过拟合.比如,尽管在文本分类中通常有$n\gg m$,贝叶斯逻辑回归也是一个有效的文本分类方法.



